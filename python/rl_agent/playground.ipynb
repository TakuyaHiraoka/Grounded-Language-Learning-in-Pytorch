{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vision_M(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "            Use the same hyperparameter settings denoted in the paper\n",
    "        '''\n",
    "        \n",
    "        super(Vision_M, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4 )\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2 )\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is input image with shape [3, 84, 84]\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Language_M(nn.Module):\n",
    "    def __init__(self, vocab_size=100, embed_dim=128, hidden_size=128):\n",
    "        '''\n",
    "            Use the same hyperparameter settings denoted in the paper\n",
    "        '''\n",
    "        \n",
    "        super(Language_M, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)  # 2 words in vocab, 5 dimensional embeddings\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Argument\n",
    "                x: natural language instructions encoded in word indices, has shape\n",
    "                    [batch_size, seq]\n",
    "        '''\n",
    "        embedded_input = self.embeddings(x)\n",
    "        out, hn = self.lstm(embedded_input)\n",
    "        h, c = hn\n",
    "        \n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size torch.Size([1, 10])\n",
      "Output size torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "def test_language_module():\n",
    "    test_instruction = Variable(torch.LongTensor(np.random.randint(1, 100, size=(1, 10))))\n",
    "    print('Input size', test_instruction.size())\n",
    "\n",
    "    lm = Language_M()\n",
    "    output = lm(test_instruction)\n",
    "    \n",
    "    print('Output size', output.size())\n",
    "    \n",
    "    return output\n",
    "\n",
    "l_out = test_language_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size torch.Size([1, 3, 84, 84])\n",
      "Output size torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "def test_vision_module():\n",
    "    test_input = Variable(torch.randn(1, 3, 84, 84))\n",
    "    print('Input size', test_input.size())\n",
    "\n",
    "    vm = Vision_M()\n",
    "\n",
    "    test_output = vm(test_input)\n",
    "    print('Output size', test_output.size())\n",
    "\n",
    "    return test_output\n",
    "    \n",
    "v_out = test_vision_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Mixing_M(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixing_M, self).__init__()\n",
    "\n",
    "    \n",
    "    def forward(self, visual_encoded, instruction_encoded):\n",
    "        '''\n",
    "            Argument:\n",
    "                visual_encoded: output of vision module, shape [batch_size, 64, 7, 7]\n",
    "                instruction_encoded: hidden state of language module, shape [batch_size, 1, 128]\n",
    "        '''\n",
    "        batch_size = visual_encoded.size()[0]\n",
    "        visual_flatten = visual_encoded.view(batch_size, -1)\n",
    "        instruction_flatten = instruction_encoded.view(batch_size, -1)\n",
    "                \n",
    "        mixed = torch.cat([visual_flatten, instruction_flatten], dim=1)\n",
    "        \n",
    "        return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size torch.Size([1, 3264])\n"
     ]
    }
   ],
   "source": [
    "def test_mixing_module(v_out, l_out):\n",
    "    mm = Mixing_M()\n",
    "    \n",
    "    test_output = mm(v_out, l_out)\n",
    "    print(\"Output size\", test_output.size())\n",
    "    \n",
    "    return test_output\n",
    "\n",
    "m_out = test_mixing_module(v_out, l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action_M(nn.Module):\n",
    "    def __init__(self, batch_size=1, hidden_size=256):\n",
    "        super(Action_M, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm_1 = nn.LSTMCell(input_size=3264, hidden_size=256)\n",
    "        self.lstm_2 = nn.LSTMCell(input_size=256, hidden_size=256)\n",
    "        \n",
    "        self.hidden_1 = (Variable(torch.randn(batch_size, hidden_size)), \n",
    "                        Variable(torch.randn(batch_size, hidden_size))) \n",
    "        \n",
    "        self.hidden_2 = (Variable(torch.randn(batch_size, hidden_size)), \n",
    "                        Variable(torch.randn(batch_size, hidden_size))) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Argument:\n",
    "                x: x is output from the Mixing Module, as shape [batch_size, 1, 3264]\n",
    "        '''\n",
    "        # Feed forward\n",
    "        h1, c1 = self.lstm_1(x, self.hidden_1)\n",
    "        h2, c2 = self.lstm_2(h1, self.hidden_2)\n",
    "        \n",
    "        # Update current hidden state\n",
    "        self.hidden_1 = (h1, c1)\n",
    "        self.hidden_2 = (h2, c2)\n",
    "        \n",
    "        # Return the hidden state of the upper layer\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "def test_action_module():\n",
    "    am = Action_M()\n",
    "    test_output = am(m_out)\n",
    "    print(test_output.size())\n",
    "    \n",
    "    return test_output\n",
    "\n",
    "am_output = test_action_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SavedAction = namedtuple('SavedAction', ['action', 'value'])\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, action_space):\n",
    "        super(Policy, self).__init__()\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        self.affine1 = nn.Linear(256, 128)\n",
    "        self.action_head = nn.Linear(128, action_space)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        \n",
    "        return action_scores, state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size torch.Size([1, 10]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "def test_policy():\n",
    "    policy = Policy(action_space=10)\n",
    "    test_output = policy(am_output)\n",
    "    \n",
    "    print('Output size', test_output[0].size(), test_output[1].size())\n",
    "\n",
    "    return test_output\n",
    "\n",
    "policy_output = test_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.vision_m = Vision_M()\n",
    "        self.language_m = Language_M()\n",
    "        self.mixing_m = Mixing_M()\n",
    "        self.action_m = Action_M()\n",
    "        \n",
    "        self.policy = Policy(action_space=10)\n",
    "        \n",
    "    def forward(self, img, instruction):\n",
    "        '''\n",
    "        Argument:\n",
    "        \n",
    "            img: environment image, shape [batch_size, 3, 84, 84]\n",
    "            instruction: natural language instruction [batch_size, seq]\n",
    "        '''\n",
    "        \n",
    "        vision_out = self.vision_m(img)\n",
    "        language_out = self.language_m(instruction)\n",
    "        mix_out = self.mixing_m(vision_out, language_out)\n",
    "        action_out = self.action_m(mix_out)\n",
    "        \n",
    "        action_prob, value = self.policy(action_out)\n",
    "        \n",
    "        return action_prob, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 1])\n",
      "[[-0.07670651 -0.10970842  0.03437663 -0.10954983 -0.03560381 -0.11679479\n",
      "   0.05895545  0.06801075  0.12713522 -0.1156317 ]] [[-0.14793287]]\n"
     ]
    }
   ],
   "source": [
    "def test_model():\n",
    "    model = Model()\n",
    "    \n",
    "    vision = Variable(torch.randn(1, 3, 84, 84))\n",
    "    instruction = Variable(torch.LongTensor(np.random.randint(1, 100, size=(1, 10))))\n",
    "    \n",
    "    probs, value = model(vision, instruction)\n",
    "    \n",
    "    print(probs.size(), value.size())\n",
    "    print(probs.data.numpy(), value.data.numpy())\n",
    "    \n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FakeEnvironment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.generate_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        return self.generate_state(), 2, False, 1\n",
    "        \n",
    "    def generate_state(self):\n",
    "        vision = Variable(torch.randn(1, 3, 84, 84))\n",
    "        instruction = Variable(torch.LongTensor(np.random.randint(1, 100, size=(1, 10))))\n",
    "        \n",
    "        return (vision, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "gamma = 0.99\n",
    "tau = 1.0\n",
    "model = Model()\n",
    "#model = ActorCritic(env.observation_space.shape[0], env.action_space)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.train()\n",
    "\n",
    "env = FakeEnvironment()\n",
    "state = env.reset()\n",
    "done = True\n",
    "\n",
    "episode_length = 0\n",
    "while True:\n",
    "    episode_length += 1\n",
    "\n",
    "    values = []\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    entropies = []\n",
    "\n",
    "    # Loop for number of unrolling steps\n",
    "    for step in range(50):\n",
    "        logit, value = model(*state)\n",
    "        \n",
    "        # Calculate entropy from action probability distribution\n",
    "        prob = F.softmax(logit)\n",
    "        log_prob = F.log_softmax(logit)\n",
    "        entropy = -(log_prob * prob).sum(1)\n",
    "        entropies.append(entropy)\n",
    "\n",
    "        # Take the action from distribution\n",
    "        action = prob.multinomial().data\n",
    "        log_prob = log_prob.gather(1, Variable(action))\n",
    "\n",
    "        # Perform the action on the environment\n",
    "        state, reward, done, _ = env.step(action.numpy())\n",
    "        done = done or episode_length >= 100\n",
    "        \n",
    "        if done:\n",
    "            episode_length = 0\n",
    "            state = env.reset()\n",
    "\n",
    "        values.append(value)\n",
    "        log_probs.append(log_prob)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Terminal state or reached number of unrolling steps, whichever comes first\n",
    "    R, gae = Variable(torch.zeros(1, 1)), torch.zeros(1, 1)\n",
    "    \n",
    "    # Get value estimate of current state\n",
    "    if not done:\n",
    "        _, R = model(*state)\n",
    "\n",
    "    values.append(R)\n",
    "    policy_loss, value_loss = 0, 0\n",
    "\n",
    "    # Performing update\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        # Value function loss\n",
    "        R = gamma * R + rewards[i]\n",
    "        value_loss = value_loss + 0.5 * (R - values[i]).pow(2)\n",
    "\n",
    "        # Generalized Advantage Estimataion\n",
    "        delta_t = rewards[i] + gamma * \\\n",
    "                values[i + 1].data - values[i].data\n",
    "        gae = gae * gamma * tau + delta_t\n",
    "\n",
    "        # Computing policy loss\n",
    "        policy_loss = policy_loss - \\\n",
    "            log_probs[i] * Variable(gae) - 0.01 * entropies[i]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Back-propagation\n",
    "    (policy_loss + 0.5 * value_loss).backward()\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), 40)\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    # This is only for testing\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
